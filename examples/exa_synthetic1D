using Random
using LinearAlgebra
using JuMP
using Gurobi
using PyPlot

Random.seed!(0)

include("../src/PWARegression.jl")
PWAR = PWARegression

const GUROBI_ENV = Gurobi.Env()
solver() = Model(optimizer_with_attributes(
    () -> Gurobi.Optimizer(GUROBI_ENV), "OutputFlag"=>false
))

NT = PWAR.Node{Vector{Float64},Float64}
nodes = NT[]
for xt in Iterators.product(0:0.05:1, (1.0,))
    local x = collect(xt)
    local η = sin(xt[1]*7) + 2
    push!(nodes, PWAR.Node(x, η))
end

fig0 = figure(0)
ax0 = fig0.add_subplot()
for node in nodes
    ax0.plot(node.x[1], node.η, ls="none", marker=".", ms=5, c="tab:blue")
end

# local_L2_residual

inodes_all = BitSet(1:length(nodes))
σ = 0.05
β = 1e-6

nplot = 100
x1_ = range(-0.1, 1.1, length=nplot)
Xt_ = Iterators.product(x1_)
X1_ = getindex.(Xt_, 1)
RES_ = fill(NaN, size(Xt_))

for (k, xt) in enumerate(Xt_)
    local xc = [xt..., 1.0]
    local res = PWAR.local_L2_residual(nodes, inodes_all, xc, σ, β, 2)
    RES_[k] = sqrt(res)
end

ax0t = ax0.twinx()
ax0t.plot(X1_, RES_, c="r")

# regions

ϵ = 0.15
BD = 100
γ = 0.01
δ = 1e-5
# inodes_list = PWAR.maximal_regions(
#     nodes, ϵ, BD, σ, β, γ, δ, 2, solver, solver
# )
inodes_list = PWAR.greedy_covering(
    nodes, ϵ, BD, σ, β, γ, δ, 2, solver, solver
)
inodes_list = PWAR.optimal_covering(
    nodes, ϵ, BD, σ, β, γ, δ, 2, solver, solver, solver
)

bs = PWAR.optimal_set_cover(length(nodes), inodes_list, solver)
inodes_list_opt = BitSet[]
for (k, b) in enumerate(bs)
    if round(Int, b) == 1
        push!(inodes_list_opt, inodes_list[k])
    end
end
inodes_list_opt

fig1 = figure(1)
ax1 = fig1.add_subplot()
colors = collect(keys(matplotlib.colors.TABLEAU_COLORS))

for (k, inodes) in enumerate(inodes_list)
    local c = colors[mod(k - 1, length(colors)) + 1]
    local lb = Inf
    local ub = -Inf
    for inode in inodes
        local x = nodes[inode].x
        if x[1] < lb
            lb = x[1]
        end
        if x[1] > ub
            ub = x[1]
        end
    end
    local x1rect = (lb, ub, ub, lb, lb)
    local x2rect = (k - 0.2, k - 0.2, k + 0.2, k + 0.2, k - 0.2)
    ax1.plot(x1rect, x2rect, c=c)
end

# Plot planes

nplot = 5

for inodes in inodes_list_opt
    # optim parameters
    local model = solver()
    local a = @variable(model, [1:2], lower_bound=-BD, upper_bound=BD)
    local r = @variable(model, lower_bound=-1)
    for inode in inodes
        local node = nodes[inode]
        @constraint(model, dot(a, node.x) ≤ node.η + r)
        @constraint(model, dot(a, node.x) ≥ node.η - r)
    end
    @objective(model, Min, r)
    optimize!(model)
    @assert termination_status(model) == OPTIMAL
    @assert primal_status(model) == FEASIBLE_POINT
    local a_opt = value.(a)
    # plot
    local lb = Inf
    local ub = -Inf
    for inode in inodes
        local x = nodes[inode].x
        if x[1] < lb
            lb = x[1]
        end
        if x[1] > ub
            ub = x[1]
        end
    end
    local x1_ = range(lb, ub, length=nplot)
    local Xt_ = Iterators.product(x1_)
    local X1_ = getindex.(Xt_, 1)
    local Y_ = map(xt -> dot(a_opt, (xt..., 1.0)), Xt_)
    ax0.plot(X1_, Y_, ls="solid")
end

fig0.savefig(
    "./examples/figures/exa_synthetic1D.png", bbox_inches="tight", dpi=100
)